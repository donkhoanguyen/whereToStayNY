{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20d736c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "def get_token(path='mapbox_access_token.txt'):\n",
    "    \n",
    "    '''\n",
    "    Retrieve the mapbox access token.\n",
    "    \n",
    "    Args: path (string) - path to the text file with the Mapbox access token\n",
    "    \n",
    "    Returns: Mapbox access token (string)\n",
    "    '''\n",
    "    \n",
    "    with open(path) as key:\n",
    "        return key.read()\n",
    "    \n",
    "    \n",
    "def desc_byhost(df, col, host_col='by_superhost'):\n",
    "    \n",
    "    '''\n",
    "    Calculate descriptive statistics for a dataframe's column for regular hosts \n",
    "    and superhosts.\n",
    "    \n",
    "    Args: df (Pandas dataframe)\n",
    "          col (string) - name of column to describe\n",
    "          host_col (string) - name of the superhost column\n",
    "          \n",
    "    Returns: descriptive statistics of the selected column separated by the host \n",
    "             column (Pandas dataframe)\n",
    "    '''\n",
    "    \n",
    "    frame = df[df[host_col] == 0][[col]].describe()\n",
    "    frame.columns = ['regular_hosts']\n",
    "    frame['superhosts'] = df.loc[df[host_col] == 1, col].describe()\n",
    "    return frame\n",
    "\n",
    "\n",
    "def sample_byinterval(df, col, lower, upper, step, size=100):\n",
    "    \n",
    "    '''\n",
    "    Downsample a dataframe's column in intervals.\n",
    "    \n",
    "    Args: df (Pandas dataframe)\n",
    "          col (string) - name of column to sample\n",
    "          lower (integer) - lower bound of the first interval\n",
    "          upper (integer) - upper bound of the last interval\n",
    "          step (integer) - size of each interval\n",
    "          size (integer) - size of each sample\n",
    "    \n",
    "    Returns: downsampled data (Pandas dataframe)\n",
    "    '''\n",
    "    \n",
    "    samples = [df[df[col] < lower].copy()]\n",
    "    for r in range(lower, upper, step):\n",
    "        samp = df[(df[col] > r) & (df[col] <= r + step)].copy().sample(size, random_state=0)\n",
    "        samples.append(samp)\n",
    "    return pd.concat(samples)\n",
    "\n",
    "\n",
    "def agg_to_2cols(df, agg_col, agg_col_name, groupby_col='neighborhood', \n",
    "                 groupby_col_name='Neighborhood', agg_by_mean=True, round_to=2):\n",
    "    \n",
    "    '''\n",
    "    Aggregate a dataframe into 2 columns - grouping by 1 and aggregating the other \n",
    "    by either the mean or count.\n",
    "    \n",
    "    Args: df (Pandas dataframe)\n",
    "          agg_col (string) - name of column to aggregate\n",
    "          agg_col_name (string) - name of aggregated column in the resulting \n",
    "                                  dataframe\n",
    "          groupby_col (string) - name of column to group by\n",
    "          groupby_col_name (string) - name of grouped column in the resulting \n",
    "                                      dataframe\n",
    "          agg_by_mean (boolean) - whether to aggregate using the mean, else use \n",
    "                                  the count\n",
    "          round_to (integer) - number of digits to round to if aggregating using \n",
    "                               the mean\n",
    "                                  \n",
    "    Returns: Aggregated data in 2 columns (pandas dataframe)\n",
    "    '''\n",
    "    \n",
    "    if agg_by_mean:\n",
    "        frame = df.groupby(groupby_col)[[agg_col]].mean().round(round_to).sort_values(agg_col, ascending=False).reset_index()\n",
    "    else:\n",
    "        frame = df.groupby(groupby_col)[[agg_col]].count().sort_values(agg_col, ascending=False).reset_index()\n",
    "        \n",
    "    frame.columns = [groupby_col_name, agg_col_name]\n",
    "    return frame\n",
    "\n",
    "\n",
    "def dup_feats(df):\n",
    "    \n",
    "    '''\n",
    "    Find duplicated features in a dataframe.\n",
    "    \n",
    "    Args: df (Pandas dataframe)\n",
    "    \n",
    "    Returns: Pairs of duplicated features (list[list[string]: length 2])\n",
    "    '''\n",
    "    \n",
    "    cols = df.columns.tolist()\n",
    "    dup = []\n",
    "    \n",
    "    for i in range(len(cols) - 1):\n",
    "        for j in range(i + 1, len(cols)):\n",
    "            if df[cols[i]].equals(df[cols[j]]):\n",
    "                dup.append([cols[i], cols[j]])\n",
    "                \n",
    "    return dup if len(dup) else None\n",
    "\n",
    "\n",
    "def const_feats(df, threshold=0.05):\n",
    "    \n",
    "    '''\n",
    "    Find constant and quasi-constant features. A feature is considered \n",
    "    quasi-constant if its variance is less than the defined threshold.\n",
    "    \n",
    "    Args: df (Pandas dataframe)\n",
    "          threshold (float) - variance threshold to consider a feature \n",
    "                              quasi-constant\n",
    "                              \n",
    "    Returns: List of constant and quasi-constant features (list[string])\n",
    "    '''\n",
    "    \n",
    "    const = df.var()[df.var() < threshold].index.tolist()\n",
    "    return const if len(const) else None\n",
    "\n",
    "\n",
    "def const_cat_feats(df, threshold=0.95):\n",
    "    \n",
    "    '''\n",
    "    Find constant and quasi-constant categorical features. A feature is \n",
    "    considered quasi-constant if any of its values has a relative count \n",
    "    greater than the defined threshold.\n",
    "    \n",
    "    Args: df (Pandas dataframe)\n",
    "          threshold (float) - relative count threshold to consider a feature \n",
    "                              quasi-constant\n",
    "                              \n",
    "    Returns: List of constant and quasi-constant features (list[string])\n",
    "    '''\n",
    "    \n",
    "    cols = df.dtypes[df.dtypes == 'object'].index.tolist()\n",
    "    const = []\n",
    "    \n",
    "    for col in cols:\n",
    "        value_pct = df[col].value_counts() / df.shape[0]\n",
    "        if value_pct[0] > threshold:\n",
    "            const.append(col)\n",
    "            \n",
    "    return const if len(const) else None\n",
    "\n",
    "\n",
    "def corr_feats(df, threshold=0.5):\n",
    "    \n",
    "    '''\n",
    "    Find correlated features.\n",
    "    \n",
    "    Args: df (Pandas dataframe)\n",
    "          threshold (float) - threshold for correlation coefficient\n",
    "          \n",
    "    Returns: Pairs of correlated features (list[list[string, string, float]])\n",
    "    '''\n",
    "    \n",
    "    feats = df.columns.tolist()\n",
    "    corr = []\n",
    "    \n",
    "    for i in range(len(feats) - 1):\n",
    "        for j in range(i + 1, len(feats)):\n",
    "            coef = abs(df[feats[i]].corr(df[feats[j]]))\n",
    "            if coef > threshold:\n",
    "                corr.append([feats[i], feats[j], coef])\n",
    "    \n",
    "    return corr if len(corr) else None\n",
    "\n",
    "\n",
    "def check_nb(row, tier, nb_list, nb_col='neighborhood', tier_col='price_tier'):\n",
    "    \n",
    "    '''\n",
    "    Helper function to assign a price tier to a listing if its\n",
    "    neighborhood is in the given list. This helper function is to be passed\n",
    "    into a Pandas dataframe's apply method with an axis argument of 1.\n",
    "    \n",
    "    Args: row (row in Pandas dataframe)\n",
    "          tier (integer) - tier value to assign to the listing\n",
    "          nb_list (list[string]) - list of neighborhoods in a certain tier\n",
    "          nb_col (string) - name of neighborhood column\n",
    "          tier_col (string) - name of price tier column\n",
    "          \n",
    "    Returns: Price tier value (integer)\n",
    "    '''\n",
    "    \n",
    "    return tier if row[nb_col] in nb_list else row[tier_col]\n",
    "\n",
    "\n",
    "def onehot_encoder(df, var_list, num_lab=2, drop_og=True):\n",
    "    \n",
    "    '''\n",
    "    One-hot encode a given list of categorical variables. Only the most \n",
    "    frequent labels will be encoded for each variable. The number of labels\n",
    "    to encode is 2 by default.\n",
    "    \n",
    "    Args: df (Pandas dataframe)\n",
    "          var_list (list[string]) - list of categorical variables to \n",
    "                                    one-hot encode\n",
    "          num_lab (integer) - number of labels to encode for each variable\n",
    "          drop_og (boolean) - whether to drop the original categorical\n",
    "                              column after encoding it\n",
    "                            \n",
    "    Returns: Data with categorical variables one-hot encoded (Pandas dataframe)\n",
    "    '''\n",
    "    \n",
    "    df = df.copy()\n",
    "    \n",
    "    for var in var_list:\n",
    "        labels = df[var].value_counts().index[:num_lab]\n",
    "        \n",
    "        for lab in labels:\n",
    "            df[var + '_' + lab] = df[var].apply(lambda x: 1 if x == lab else 0)\n",
    "            \n",
    "    if drop_og:\n",
    "        df.drop(var_list, axis=1, inplace=True)\n",
    "        \n",
    "    return df\n",
    "\n",
    "\n",
    "def log_transform(series, inverse=False):\n",
    "    \n",
    "    '''\n",
    "    Log transform a series or inverse-log transform.\n",
    "    \n",
    "    Args: series (Pandas series)\n",
    "          inverse (boolean) - whether to inverse-log transform\n",
    "          \n",
    "    Return: transformed series (Pandas series)\n",
    "    '''\n",
    "    \n",
    "    series = series.copy()\n",
    "    if inverse:\n",
    "        return np.exp(series)\n",
    "    return np.log(series)\n",
    "\n",
    "\n",
    "def feat_coefs(feats, coefs, feat_name='feat', coef_name='coef', sort=True):\n",
    "    \n",
    "    '''\n",
    "    Show the coefficient of each feature.\n",
    "    \n",
    "    Args: feats (list[string]) - list of feature names\n",
    "          coefs (list[float]) - list of coefficients\n",
    "          feat_name (string) - name of feature column in resulting dataframe\n",
    "          coef_name (string) - name of coefficient column in resulting dataframe\n",
    "          sort (boolean) - whether to sort the coefficients in descending order\n",
    "          \n",
    "    Returns: Features and their corresponding coefficient (Pandas dataframe)\n",
    "    '''\n",
    "    \n",
    "    df = pd.DataFrame(zip(feats, coefs), columns=[feat_name, coef_name])\n",
    "    if sort:\n",
    "        df.sort_values(coef_name, ascending=False, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def make_pred(model, df_test, df_train=None, inverse_transform=True):\n",
    "    \n",
    "    '''\n",
    "    Make predictions using a specified model for the test set and optionally\n",
    "    the train set. If only the test set is passed in, an array containing 1 will \n",
    "    be returned for the train predictions.\n",
    "    \n",
    "    Args: model (Sklearn model instance) - model to predict with\n",
    "          df_test (Pandas dataframe) - test set\n",
    "          df_train (Pandas dataframe) - train set\n",
    "          inverse_transform (boolean) - whether to inverse-log-transform the\n",
    "                                        predictions\n",
    "                                        \n",
    "    Returns: predictions for the test and train sets\n",
    "             (list[Pandas series]: length 2)\n",
    "    '''\n",
    "    \n",
    "    pred_test = model.predict(df_test)\n",
    "    pred_train = [1] if df_train is None else model.predict(df_train)\n",
    "    \n",
    "    if inverse_transform:\n",
    "        pred_test = log_transform(pred_test, inverse=True)\n",
    "        pred_train = log_transform(pred_train, inverse=True)\n",
    "        \n",
    "    return pred_test, pred_train\n",
    "\n",
    "\n",
    "def score_rmse(true_test, pred_test, true_train=[1], pred_train=[1], log_true=True, log_pred=False):\n",
    "    \n",
    "    '''\n",
    "    Calculate the root mean squared error for the test set and optionally the\n",
    "    train set. This function calculates the RMSE for true values, so if any\n",
    "    input set(s) are log-transformed, they will be inverse-log-transformed\n",
    "    before the RMSE is calculated. If only the test sets are passed in, the\n",
    "    RMSE for the train set will be returned as 0.\n",
    "    \n",
    "    Args: true_test (Pandas series) - true target variable from test set\n",
    "          pred_test (Pandas series) - predicted target variable from test set\n",
    "          true_train (Pandas series) - true target variable from train set\n",
    "          pred_train (Pandas series) - predicted target variable from train set\n",
    "          log_true (boolean) - whether the input true set(s) are log-transformed\n",
    "          log_pred (boolean) - whether the input predicted set(s) are log-transformed\n",
    "    \n",
    "    Returns: root mean squared error for the test and train sets \n",
    "             (list[float]: length 2)\n",
    "    '''\n",
    "    \n",
    "    if log_true:\n",
    "        true_test = log_transform(true_test, inverse=True)\n",
    "        true_train = log_transform(true_train, inverse=True)\n",
    "        \n",
    "    if log_pred:\n",
    "        pred_test = log_transform(pred_test, inverse=True)\n",
    "        pred_train = log_transform(pred_train, inverse=True)\n",
    "        \n",
    "    rmse_test = np.sqrt(mean_squared_error(true_test, pred_test))\n",
    "    rmse_train = np.sqrt(mean_squared_error(true_train, pred_train))\n",
    "    return rmse_test, rmse_train\n",
    "\n",
    "\n",
    "def score_model(model, xtest, ytest, xtrain=None, ytrain=[1], toprint=True):\n",
    "    \n",
    "    '''\n",
    "    Score a model with the R2 score and root mean squared error for the test set\n",
    "    and optionally the train set. If only the test sets are passed in, both the\n",
    "    R2 score and RMSE for the train set will be returned as 0.\n",
    "    \n",
    "    Args: model (Sklearn model instance) - model to score\n",
    "          xtest (Pandas dataframe) - test set\n",
    "          ytest (Pandas series) - test target\n",
    "          xtrain (Pandas dataframe) - train set\n",
    "          yterain (Pandas series) - train target\n",
    "          \n",
    "    Returns: R2 score and root mean squared error for the test and train sets \n",
    "             (list[float]: length 4)\n",
    "    '''\n",
    "    \n",
    "    # R2 score\n",
    "    \n",
    "    ptest, ptrain = make_pred(model=model, df_test=xtest, df_train=xtrain)\n",
    "    rmse_test, rmse_train = score_rmse(true_test=ytest, pred_test=ptest, true_train=ytrain, pred_train=ptrain)\n",
    "    \n",
    "    r2_train = 0\n",
    "    if xtrain is not None:\n",
    "        r2_train = model.score(xtrain, ytrain)\n",
    "        if toprint:\n",
    "            print('Train R2 Score:', r2_train)\n",
    "            print('Train RMSE:', rmse_train)\n",
    "            print()\n",
    "    \n",
    "    r2_test = model.score(xtest, ytest)\n",
    "    if toprint:\n",
    "        print('R2 Score:', r2_test)\n",
    "        print('RMSE:', rmse_test)\n",
    "    \n",
    "    return r2_test, rmse_test, r2_train, rmse_train\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466cf75e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
